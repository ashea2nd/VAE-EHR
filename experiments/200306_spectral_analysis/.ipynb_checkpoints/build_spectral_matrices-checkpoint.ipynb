{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../../src\")\n",
    "from visualizer_helper import Visualizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy\n",
    "import pickle\n",
    "import os\n",
    "from annoy import AnnoyIndex\n",
    "from scipy.sparse.linalg import inv\n",
    "import hdbscan\n",
    "\n",
    "large_file_path = \"./../../../large_data_files\"\n",
    "# /data1/andrew/meng/mixehr/meng/large_data_files\n",
    "k_neighbors = 50\n",
    "k_neighbors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_icd_sparse_path = \"./../../data/PATIENT_ICD_BINARY_SPARSE_CSR.p\"\n",
    "pdata = pickle.load(open(patient_icd_sparse_path, \"rb\"))\n",
    "pdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Build L Matrix\n",
    "ANNOY_PATH = \"../../../large_data_files\"\n",
    "annoy_path = os.path.join(ANNOY_PATH, \"200214_patient_similarity_clusters_default.ann\")\n",
    "\n",
    "cos_knn_tree = AnnoyIndex(pdata.shape[1], \"angular\")\n",
    "cos_knn_tree.load(annoy_path)\n",
    "\n",
    "gamma = 2\n",
    "print(\"Building dense data matrix with k={} nn...\".format(k_neighbors))\n",
    "A = np.zeros((pdata.shape[0], pdata.shape[0]))\n",
    "for i in tqdm(range(pdata.shape[0])):\n",
    "    nn_idxs = cos_knn_tree.get_nns_by_item(i, k_neighbors)[1:]\n",
    "    cos_distances = [cos_knn_tree.get_distance(i, nn) for nn in nn_idxs]\n",
    "    rbf_distances = [np.exp(-gamma*cos_dist**2) for cos_dist in cos_distances]\n",
    "    A[i, nn_idxs] = rbf_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_adj = {}\n",
    "for i in tqdm(range(A.shape[0])):\n",
    "    nn_idx = set(np.nonzero(A[i])[0])\n",
    "    knn_adj[i] = nn_idx\n",
    "    \n",
    "for i in tqdm(range(A.shape[0])):\n",
    "    nns = knn_adj[i]\n",
    "    for nn in nns:\n",
    "        if i not in knn_adj[nn]:\n",
    "            A[i, nn] = 0\n",
    "\n",
    "pickle.dump(csr_matrix(A), open(\"./data/A_mknn_K{}_CSR.p\".format(k_neighbors - 1), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A = pickle.load(open(\"A_sym_K{}_CSR.p\".format(k_neighbors - 1), \"rb\"))\n",
    "# A_nns_per_node = [np.nonzero(row)[0].shape[0] for row in A]\n",
    "A = pickle.load(open(\"./data/A_mknn_K{}_CSR.p\".format(k_neighbors - 1), \"rb\"))\n",
    "D = np.zeros((A.shape[0], A.shape[0]))\n",
    "for i in tqdm(range(A.shape[0])):\n",
    "    D[i, i] = np.sum(A[i])\n",
    "    \n",
    "pickle.dump(csr_matrix(D), open(\"./data/D_mknn_K{}_CSR.p\".format(k_neighbors - 1), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './../../large_data_files/A_mknn_K2000_CSR.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7fcaf3d70602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# A = pickle.load(open(\"./data/A_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m A = pickle.load(open(os.path.join(large_file_path, \"A_mknn_K{}_CSR.p\".format(k_neighbors)),\n\u001b[0;32m----> 4\u001b[0;31m                      \"rb\"))\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/D_mknn_K{}_CSR.p\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './../../large_data_files/A_mknn_K2000_CSR.p'"
     ]
    }
   ],
   "source": [
    "k_neighbors = 2000\n",
    "# A = pickle.load(open(\"./data/A_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\"))\n",
    "A = pickle.load(open(os.path.join(large_file_path, \"A_mknn_K{}_CSR.p\".format(k_neighbors)),\n",
    "                     \"rb\"))\n",
    "D = pickle.load(open(\"./data/D_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mknn_nns_per_node = [np.nonzero(row)[0].shape[0] for row in A]\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.distplot(mknn_nns_per_node, kde=False)\n",
    "ax.set(xlabel=\"Nearest Neighbors\", ylabel=\"Patients\")\n",
    "plt.savefig(\"./figures/mknn_featdist_K{}.png\".format(k_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_idx = np.diag_indices(D.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.109498838418094"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_idx = np.nonzero(D)\n",
    "D_mean = np.mean(D[diag_idx])\n",
    "D_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_mc = D.copy()\n",
    "D_mc[diag_idx] = D[diag_idx] + D_mean\n",
    "print(np.mean(D_mc[nonzero_idx]), np.mean(D[nonzero_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(csr_matrix(D_mc), open(\"./data/D_mc_mknn_K{}_CSR.p\".format(k_neighbors), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D_inv_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors = 2000\n",
    "use_mc = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mc:\n",
    "    D = pickle.load(open(\"./data/D_mc_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\"))\n",
    "else:\n",
    "    D = pickle.load(open(\"./data/D_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_idx = np.nonzero(D)\n",
    "D_diag_sqrt_inv = 1.0/np.sqrt(D[nonzero_idx])\n",
    "D_inv_sqrt = D.copy()\n",
    "D_inv_sqrt[nonzero_idx] = D_diag_sqrt_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mc:\n",
    "    pickle.dump(D_inv_sqrt, open(\"./data/D_mc_mknn_inv_sqrt_K{}_CSR.p\".format(k_neighbors), \"wb\"))\n",
    "else:\n",
    "    pickle.dump(D_inv_sqrt, open(\"./data/D_mknn_inv_sqrt_K{}_CSR.p\".format(k_neighbors), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute normalized L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors = 2000\n",
    "# A = pickle.load(open(\"./data/A_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\"))\n",
    "A = pickle.load(open(os.path.join(large_file_path, \"A_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\"))\n",
    "\n",
    "if use_mc:\n",
    "    D_inv_sqrt = pickle.load(open(\"./data/D_mc_mknn_inv_sqrt_K{}_CSR.p\".format(k_neighbors), \"rb\"))\n",
    "else:\n",
    "    D_inv_sqrt = pickle.load(open(\"./data/D_mknn_inv_sqrt_K{}_CSR.p\".format(k_neighbors), \"rb\"))\n",
    "\n",
    "print(\"computing L...\")\n",
    "L = D_inv_sqrt.dot(A.dot(D_inv_sqrt))\n",
    "print(\"Done.\")\n",
    "\n",
    "if use_mc:\n",
    "    pickle.dump(csr_matrix(L), open(\"./data/L_mc_mknn_K{}_CSR.p\".format(k_neighbors), \"wb\"))\n",
    "else:\n",
    "    pickle.dump(csr_matrix(L), open(\"./data/L_mknn_K{}_CSR.p\".format(k_neighbors), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigen Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors = 50\n",
    "if use_mc:\n",
    "    L = pickle.load(open(\"./data/L_mc_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\")).toarray()\n",
    "else:\n",
    "    L = pickle.load(open(\"./data/L_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\")).toarray()\n",
    "\n",
    "print(\"Found nans:\", np.any(np.isnan(L)))\n",
    "\n",
    "evals=100\n",
    "L_evals, L_evecs = scipy.sparse.linalg.eigsh(L, k=evals + 1, which=\"LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "L_nan_idxs = np.argwhere(np.isnan(L_evals))\n",
    "print(\"Nans shape:\", L_nan_idxs.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = sns.scatterplot(range(L_evals.shape[0]), L_evals)\n",
    "ax.set(xlabel=\"Eigenvalue Number 0 - {}\".format(evals + 1))\n",
    "if use_mc:\n",
    "    plt.savefig(\"./figures/evals_L_mc_evals{}_K{}.png\".format(evals, k_neighbors))\n",
    "else:\n",
    "    plt.savefig(\"./figures/evals_L_evals{}_K{}.png\".format(evals, k_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors = 50\n",
    "L_mc = pickle.load(open(\"./data/L_mc_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\")).toarray()\n",
    "L = pickle.load(open(\"./data/L_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\")).toarray()\n",
    "A = pickle.load(open(\"./data/A_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\"))\n",
    "D = pickle.load(open(\"./data/D_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors = 2000\n",
    "if use_mc:\n",
    "    L = pickle.load(open(\"./data/L_mc_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\")).toarray()\n",
    "else:\n",
    "    L = pickle.load(open(\"./data/L_mknn_K{}_CSR.p\".format(k_neighbors), \"rb\")).toarray()\n",
    "\n",
    "print(\"Found nans:\", np.any(np.isnan(L)))\n",
    "\n",
    "evals=50\n",
    "L_evals, L_evecs = scipy.sparse.linalg.eigsh(L[:100, :100], k=evals + 1, which=\"LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(L[:1000, :1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[:, 1].toarray().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_flat = L[np.nonzero(L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(L), np.max(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(range(L_flat.shape), L.toarray().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[np.nonzero(D)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(D)\n",
    "sns.scatterplot(D[:, 1].toarray().flatten(), L[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_diag = np.array(D[np.nonzero(D)]).flatten()\n",
    "A_nz = np.array(A[np.nonzero(A)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(range(D_diag.shape[0]), D_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(range(A_nz.shape[0]), A_nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L_evals[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_k_evals = 16\n",
    "top_k_evecs=3\n",
    "knn_clusters = 4\n",
    "lc=100\n",
    "visualizer = Visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Correction?\", use_mc)\n",
    "print(\"K\", k_neighbors)\n",
    "print(\"drop_k_evals\", drop_k_evals)\n",
    "print(\"top_k_evecs\", top_k_evecs)\n",
    "print(\"knn_clusters\", knn_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_top_k = L_evecs[:, -drop_k_evals-top_k_evecs:-drop_k_evals]\n",
    "L_evecs_lengths_top_k = np.linalg.norm(X_top_k, axis=1)\n",
    "Y_top_k = X_top_k / L_evecs_lengths_top_k[:, None]\n",
    "\n",
    "print(X_top_k.shape)\n",
    "print(Y_top_k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mc:\n",
    "    Y_umap_2d = pickle.load(open(\"./data/Y_umap_2d_mc_K{}_topkevecs{}_lc{}.p\".format(k_neighbors, top_k_evecs, lc), 'rb'))\n",
    "    Y_umap_3d = pickle.load(open(\"./data/Y_umap_3d_mc_K{}_topkevecs{}_lc{}.p\".format(k_neighbors, top_k_evecs, lc), 'rb'))\n",
    "else:\n",
    "    Y_umap_2d = pickle.load(open(\"./data/Y_umap_2d_K{}_topkevecs{}_lc{}.p\".format(k_neighbors, top_k_evecs, lc), 'rb'))\n",
    "    Y_umap_3d = pickle.load(open(\"./data/Y_umap_3d_K{}_topkevecs{}_lc{}.p\".format(k_neighbors, top_k_evecs, lc), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_umap_2d = visualizer.umap_embedding(Y_top_k, n_components=2, lc=lc)\n",
    "Y_umap_3d = visualizer.umap_embedding(Y_top_k, n_components=3, lc=lc)\n",
    "\n",
    "if use_mc:\n",
    "    pickle.dump(Y_umap_2d, open(\"./data/Y_umap_2d_mc_K{}_topkevecs{}_lc{}.p\".format(k_neighbors, top_k_evecs, lc), 'wb'))\n",
    "    pickle.dump(Y_umap_3d, open(\"./data/Y_umap_3d_mc_K{}_topkevecs{}_lc{}.p\".format(k_neighbors, top_k_evecs, lc), 'wb'))\n",
    "else:\n",
    "    pickle.dump(Y_umap_2d, open(\"./data/Y_umap_2d_K{}_topkevecs{}_lc{}.p\".format(k_neighbors, top_k_evecs, lc), 'wb'))\n",
    "    pickle.dump(Y_umap_3d, open(\"./data/Y_umap_3d_K{}_topkevecs{}_lc{}.p\".format(k_neighbors, top_k_evecs, lc), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_mc:\n",
    "    Y_cluster_labels = pickle.load(open(\"./data/cluster_labels_mc_K{}_knn{}_topkevecs{}.p\".format(k_neighbors, knn_clusters, top_k_evecs), 'rb'))\n",
    "else:\n",
    "    Y_cluster_labels = pickle.load(open(\"./data/cluster_labels_K{}_knn{}_topkevecs{}.p\".format(k_neighbors, knn_clusters, top_k_evecs), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_kmeans_top_k = KMeans(n_clusters=knn_clusters).fit(Y_top_k)\n",
    "Y_cluster_labels = Y_kmeans_top_k.labels_\n",
    "\n",
    "if use_mc:\n",
    "    pickle.dump(Y_cluster_labels, open(\"./data/cluster_labels_mc_K{}_knn{}_topkevecs{}.p\".format(k_neighbors, knn_clusters, top_k_evecs), \"wb\"))\n",
    "else:\n",
    "    pickle.dump(Y_cluster_labels, open(\"./data/cluster_labels_K{}_knn{}_topkevecs{}.p\".format(k_neighbors, knn_clusters, top_k_evecs), \"wb\"))\n",
    "print(\"Cluster labels:\", np.unique(Y_cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "\n",
    "if use_mc:\n",
    "    filename_2d = \"./figures/umap2d_mc_K{}_topkevecs{}_knn{}\".format(k_neighbors, top_k_evecs, knn_clusters)\n",
    "    filename_3d = \"./figures/umap3d_mc_K{}_topkevecs{}_knn{}\".format(k_neighbors, top_k_evecs, knn_clusters)\n",
    "else:\n",
    "    filename_2d = \"./figures/umap2d_K{}_topkevecs{}_knn{}\".format(k_neighbors, top_k_evecs, knn_clusters)\n",
    "    filename_3d = \"./figures/umap3d_K{}_topkevecs{}_knn{}\".format(k_neighbors, top_k_evecs, knn_clusters)   \n",
    "\n",
    "visualizer.plot2d(\n",
    "    X=Y_umap_2d, \n",
    "    filename=filename_2d, \n",
    "    colors=Y_cluster_labels,\n",
    "    alpha = alpha\n",
    ")\n",
    "visualizer.plot3d(\n",
    "    X=Y_umap_3d, \n",
    "    filename=filename_3d, \n",
    "    colors=Y_cluster_labels,\n",
    "    alpha = alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvector Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs_to_plot=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Correction?\", use_mc)\n",
    "print(\"K\", k_neighbors)\n",
    "print(\"drop_k_evals\", drop_k_evals)\n",
    "print(\"top_k_evecs\", top_k_evecs)\n",
    "print(\"knn_clusters\", knn_clusters)\n",
    "print(\"evecs_to_plot\", evecs_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "ax = sns.scatterplot(range(L_evals.shape[0]), L_evals)\n",
    "ax.set(xlabel=\"Eigenvalue Number 0 - {}\".format(evals + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_top_k = L_evecs[:, -drop_k_evals-top_k_evecs:-drop_k_evals]\n",
    "k_evecs = L_evecs[:, -evecs_to_plot:]\n",
    "evec_cols = [\"Evec_{}\".format(i) for i in range(evecs_to_plot)]\n",
    "evec_df = pd.DataFrame(k_evecs, columns=evec_cols)\n",
    "\n",
    "print(evec_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = []\n",
    "for i in range(evecs_to_plot):\n",
    "    q1 = evec_df[\"Evec_{}\".format(i)].quantile(0.25)\n",
    "    q2 = evec_df[\"Evec_{}\".format(i)].quantile(0.75)\n",
    "    quantiles.append((q1, q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "evec_i = 3\n",
    "\n",
    "prev_colname = \"Evec_{}\".format(evec_i)\n",
    "next_colname = \"Evec_{}\".format(evec_i + 1)\n",
    "\n",
    "prev_quantiles = evec_df[(evec_df[prev_colname] >= quantiles[evec_i][0]) & \n",
    "                         (evec_df[prev_colname] <= quantiles[evec_i][1])]\n",
    "sns.distplot(prev_quantiles[prev_colname], kde=False, label=prev_colname, ax=axes[0])\n",
    "sns.distplot(prev_quantiles[next_colname], kde=False, label=next_colname, ax=axes[0])\n",
    "axes[0].legend()\n",
    "\n",
    "next_quantiles = evec_df[(evec_df[next_colname] >= quantiles[evec_i + 1][0]) & \n",
    "                         (evec_df[next_colname] <= quantiles[evec_i + 1][1])]\n",
    "sns.distplot(next_quantiles[prev_colname], kde=False, label=prev_colname, ax=axes[1])\n",
    "sns.distplot(next_quantiles[next_colname], kde=False, label=next_colname, ax=axes[1])\n",
    "axes[1].legend()\n",
    "\n",
    "if use_mc:\n",
    "    plt.savefig(\"./figures/evecs_distplot_{}vs{}_L_mc_K{}.png\".format(evec_i, evec_i+1, k_neighbors))\n",
    "else:\n",
    "    plt.savefig(\"./figures/evecs_distplot_{}vs{}_L_K{}.png\".format(evec_i, evec_i+1, k_neighbors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for evec_i in range(evecs_to_plot - 1):\n",
    "    evec_colname = \"Evec_{}\".format(evec_i)\n",
    "    evec_quantiles = evec_df[(evec_df[evec_colname] >= quantiles[evec_i][0]) & \n",
    "                             (evec_df[evec_colname] <= quantiles[evec_i][1])]\n",
    "    sns.pairplot(evec_quantiles[[\"Evec_{}\".format(evec_i), \"Evec_{}\".format(evec_i+1)]])\n",
    "#     if use_mc:\n",
    "#         plt.savefig(\"./figures/evecs_pairplot_{}vs{}_L_mc_K{}.png\".format(evec_i, evec_i+1, k_neighbors))\n",
    "#     else:\n",
    "#         plt.savefig(\"./figures/evecs_pairplot_{}vs{}_L_K{}.png\".format(evec_i, evec_i+1, k_neighbors))\n",
    "\n",
    "#MAKE THIS PLOT FUNCTION A BIT MORE GENERAL. U NOTICE HOW EVEC4 vs EVEC3 SAYS A LOT ABOUT HOW THE CLUSTERS CAN FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(evec_quantiles.iloc[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_umap_2d\n",
    "Y_cluster_labels\n",
    "Y_umap_2d[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "\n",
    "if use_mc:\n",
    "    filename_2d = \"./figures/umap2d_mc_K{}_topkevecs{}_lc{}_knn{}\".format(k_neighbors, top_k_evecs, lc, knn_clusters)\n",
    "    filename_3d = \"./figures/umap3d_mc_K{}_topkevecs{}_lc{}_knn{}\".format(k_neighbors, top_k_evecs, lc, knn_clusters)\n",
    "else:\n",
    "    filename_2d = \"./figures/umap2d_K{}_topkevecs{}_lc{}_knn{}\".format(k_neighbors, top_k_evecs, lc, knn_clusters)\n",
    "    filename_3d = \"./figures/umap3d_K{}_topkevecs{}_lc{}_knn{}\".format(k_neighbors, top_k_evecs, lc, knn_clusters)   \n",
    "\n",
    "data2d = {\"umap_1\": Y_umap_2d[:, 0].tolist(), \n",
    "          \"umap_2\": Y_umap_2d[:, 1].tolist(), \n",
    "          \"cluster\": Y_cluster_labels.tolist()}\n",
    "\n",
    "data3d = {\"umap_1\": Y_umap_3d[:, 0].tolist(), \n",
    "          \"umap_2\": Y_umap_3d[:, 1].tolist(), \n",
    "          \"umap_3\": Y_umap_3d[:, 2].tolist(), \n",
    "          \"cluster\": Y_cluster_labels.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "ax2d = sns.scatterplot(x='umap_1', y='umap_2', hue='cluster', palette=\"bright\", data=df2d)\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardized Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_standardized = pickle.load(open(\"L_standardized_sym_K{}_CSR.p\".format(k_neighbors - 1), \"rb\"))\n",
    "L_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_std = np.std(L, axis=0)\n",
    "L_mean = np.mean(L, axis=0)\n",
    "print(np.nonzero(L_std)[0])\n",
    "print(np.nonzero(L_mean)[0])\n",
    "print(np.all(np.nonzero(L_std)[0] == np.nonzero(L_mean)[0]))\n",
    "print(\"^ This means mean and std are nonzero at exactly the same places...\")\n",
    "\n",
    "L_standardized = np.subtract(L, L_mean, where=L_std!=0)\n",
    "L_standardized = np.divide(L, L_std, where=L_std!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(L_standardized[:, 67]))\n",
    "print(np.std(L_standardized[:, 67]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(csr_matrix(L_standardized), open(\"L_standardized_sym_K{}_CSR.p\".format(k_neighbors - 1), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_std = 100\n",
    "L_standardized_evals, L_standardized_evecs = scipy.sparse.linalg.eigsh(L_standardized, k=e_std)\n",
    "\n",
    "L_standardized_nan_idxs = np.argwhere(np.isnan(L_standardized_evals))\n",
    "print(\"Nans shape:\", L_standardized_nan_idxs.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(range(L_standardized_evals.shape[0]), L_standardized_evals)\n",
    "plt.savefig(\"eigen_vals_eigs{}_L_standardized_K{}.png\".format(e_std, k_neighbors - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(L_standardized_evals, open(\"L_standardized_evals_eigs{}_K{}.p\".format(e_std, k_neighbors - 1), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,1,1],[2,2,2],[3,3,3]])\n",
    "b = np.array([1,2,3])\n",
    "\n",
    "print(a / b[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = L_evecs\n",
    "L_evecs_lengths = np.linalg.norm(X, axis=1)\n",
    "\n",
    "Y = X / L_evecs_lengths[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pca = PCA().fit(Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = 5\n",
    "print(np.sum(Y_pca.explained_variance_ratio_[:n_feats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pca_feats = Y_pca.components_[:n_feats].T\n",
    "Y_pca_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "Y_kmeans = KMeans(n_clusters=n_clusters).fit(Y_pca_feats)\n",
    "Y_cluster_labels = Y_kmeans.labels_\n",
    "np.unique(Y_cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = Visualizer()\n",
    "Y_umap_2d = visualizer.umap_embedding(Y_pca_feats, n_components=2)\n",
    "Y_umap_3d = visualizer.umap_embedding(Y_pca_feats, n_components=3)\n",
    "\n",
    "pickle.dump(Y_umap_2d, open(\"Y_umap_2d_pca{}.p\".format(n_feats), 'wb'))\n",
    "pickle.dump(Y_umap_3d, open(\"Y_umap_3d_pca{}.p\".format(n_feats), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_umap_2d = pickle.load(open(\"Y_umap_2d_pca{}.p\".format(n_feats), 'rb'))\n",
    "Y_umap_3d = pickle.load(open(\"Y_umap_3d_pca{}.p\".format(n_feats), 'rb'))\n",
    "\n",
    "alpha = 1\n",
    "visualizer.plot2d(\n",
    "    X=Y_umap_2d, \n",
    "    filename=\"Patient_Clusters_2D_spectral_K{}_eig{}_pca{}_clusters{}\".format(k_neighbors - 1, eigs, n_feats, n_clusters), \n",
    "    colors=Y_cluster_labels,\n",
    "    alpha = alpha\n",
    ")\n",
    "\n",
    "visualizer.plot3d(\n",
    "    X=Y_umap_3d, \n",
    "    filename=\"Patient_Clusters_3D_spectral_K{}_eig{}_pca{}_clusters{}\".format(k_neighbors - 1, eigs, n_feats, n_clusters), \n",
    "    colors=Y_cluster_labels,\n",
    "    alpha = alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = 8\n",
    "minclustersize = 10\n",
    "\n",
    "Y_pca_feats = Y_pca.components_[:n_feats].T\n",
    "\n",
    "hdbscanner = hdbscan.HDBSCAN(min_cluster_size=minclustersize).fit(Y_pca_feats)\n",
    "hdbscan_labels = hdbscanner.fit_predict(Y_pca_feats)\n",
    "np.unique(hdbscan_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = Visualizer()\n",
    "Y_umap_2d = visualizer.umap_embedding(Y_pca_feats, n_components=2)\n",
    "Y_umap_3d = visualizer.umap_embedding(Y_pca_feats, n_components=3)\n",
    "\n",
    "pickle.dump(Y_umap_2d, open(\"Y_umap_2d_pca{}.p\".format(n_feats), 'wb'))\n",
    "pickle.dump(Y_umap_3d, open(\"Y_umap_3d_pca{}.p\".format(n_feats), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_umap_2d = pickle.load(open(\"Y_umap_2d_pca{}.p\".format(n_feats), 'rb'))\n",
    "Y_umap_3d = pickle.load(open(\"Y_umap_3d_pca{}.p\".format(n_feats), 'rb'))\n",
    "\n",
    "alpha = 1\n",
    "visualizer.plot2d(\n",
    "    X=Y_umap_2d, \n",
    "    filename=\"Patient_Clusters_2D_spectral_HDB_K{}_eig{}_pca{}_minclustersize{}\".format(k_neighbors - 1, eigs, n_feats, minclustersize), \n",
    "    colors=hdbscan_labels,\n",
    "    alpha = alpha\n",
    ")\n",
    "\n",
    "visualizer.plot3d(\n",
    "    X=Y_umap_3d, \n",
    "    filename=\"Patient_Clusters_3D_spectral_HDB_K{}_eig{}_pca{}_minclustersize{}\".format(k_neighbors - 1, eigs, n_feats, minclustersize), \n",
    "    colors=hdbscan_labels,\n",
    "    alpha = alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_idx = 0\n",
    "icd_row = A_sym[icd_idx]\n",
    "has_icd = np.nonzero(icd_row)[1]\n",
    "has_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_pdata(pdata, unwanted = set([])):\n",
    "    icd_x_patients = pdata.T\n",
    "    sorted_idx = []\n",
    "    seen = set([])\n",
    "\n",
    "    for icd_idx in tqdm(range(icd_x_patients.shape[0])):\n",
    "        if icd_idx in unwanted:\n",
    "            continue\n",
    "        icd_row = icd_x_patients[icd_idx]\n",
    "        has_icd = set(np.nonzero(icd_row)[1])\n",
    "        has_icd -= seen\n",
    "        sorted_idx += list(has_icd)\n",
    "        seen.update(sorted_idx)\n",
    "        \n",
    "    icd_x_patients_sorted = pdata[sorted_idx].T\n",
    "    print(len(seen))\n",
    "    return icd_x_patients_sorted\n",
    "\n",
    "A_sorted = sort_pdata(A_sym)\n",
    "A_sorted[A_sorted > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "sns.heatmap(A_sorted.toarray()[:2000, :2000])\n",
    "plt.savefig(\"heatmap_A_K{}.png\".format(k_neighbors - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mengp369",
   "language": "python",
   "name": "mengp369"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
